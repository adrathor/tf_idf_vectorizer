{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import math\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "from sys import getsizeof\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMPUTE IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compidf(uniq,d, data):\n",
    "    c=0\n",
    "    lstc=[]\n",
    "    for u in uniq:    \n",
    "        for i in d:\n",
    "            for j in i.keys():\n",
    "                if u== j:\n",
    "                    c+=1 #count of a word in the whole corpus\n",
    "        lstc.append(c) # list of count of a word in the whole corpus\n",
    "        c=0\n",
    "    wordcount=dict(zip(uniq,lstc)) # dict of word and their count\n",
    "    idf_val=[]\n",
    "    for i, j in wordcount.items():\n",
    "        idf= 1+ math.log((1+len(data))/(1+j)) #formula for IDF\n",
    "        idf_val.append(idf)\n",
    "    idfdict= dict(zip(uniq,idf_val))\n",
    "    return idf_val, idfdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(data):\n",
    "    d=[]\n",
    "    unique_words=set()\n",
    "    if isinstance(data,list):\n",
    "        for i in data:\n",
    "            d.append(dict(Counter(i.split()))) # d has dicts with words in the data as keys and freq as their values\n",
    "            for j in i.split(\" \"):\n",
    "                if len(j)<2:\n",
    "                    continue\n",
    "                unique_words.add(j)\n",
    "        unique_words= sorted(list(unique_words)) # it is a set of all the unique words\n",
    "        vocab= {j:i for i,j in enumerate(unique_words)} # it is a dict with keys as words and values as indexes\n",
    "        idf_val, idfdict= compidf(unique_words,d, data)\n",
    "        return unique_words, idf_val, idfdict, vocab,d\n",
    "    else:\n",
    "        print(\"wrong datatype\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "     'this is the first document',\n",
    "     'this document is the second document',\n",
    "     'and this is the third one',\n",
    "     'is this the first document',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uniq, idf_val, idfdict, vocab,d= fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'this': 1, 'is': 1, 'the': 1, 'first': 1, 'document': 1},\n",
       " {'this': 1, 'document': 2, 'is': 1, 'the': 1, 'second': 1},\n",
       " {'and': 1, 'this': 1, 'is': 1, 'the': 1, 'third': 1, 'one': 1},\n",
       " {'is': 1, 'this': 1, 'the': 1, 'first': 1, 'document': 1}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfdict[\"this\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing TF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comptf(d):\n",
    "    l=[]\n",
    "    listi=[]\n",
    "    alpha=[]\n",
    "    alphai=[]\n",
    "    for k in range(len(d)):    \n",
    "        for i,j in d[k].items():\n",
    "            tf= j/sum(d[k].values()) #formula for term frequency\n",
    "            l.append(tf) #appending tf values\n",
    "            listi.append(i) # appending words\n",
    "        alpha.append(l) #appending list of tf values\n",
    "        alphai.append(listi) #appending list of words\n",
    "        l=[]\n",
    "        listi=[]\n",
    "    return alphai, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=comptf(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['this', 'is', 'the', 'first', 'document'],\n",
       " ['this', 'document', 'is', 'the', 'second'],\n",
       " ['and', 'this', 'is', 'the', 'third', 'one'],\n",
       " ['is', 'this', 'the', 'first', 'document']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.2, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.16666666666666666,\n",
       "  0.3333333333333333,\n",
       "  0.16666666666666666,\n",
       "  0.16666666666666666,\n",
       "  0.16666666666666666],\n",
       " [0.16666666666666666,\n",
       "  0.16666666666666666,\n",
       "  0.16666666666666666,\n",
       "  0.16666666666666666,\n",
       "  0.16666666666666666,\n",
       "  0.16666666666666666],\n",
       " [0.2, 0.2, 0.2, 0.2, 0.2]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMPUTE IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compidf(uniq,d):\n",
    "    c=0\n",
    "    lstc=[]\n",
    "    for u in uniq:    \n",
    "        for i in d:\n",
    "            for j in i.keys():\n",
    "                if u== j:\n",
    "                    c+=1 #count of a word in the whole corpus\n",
    "        lstc.append(c) # list of count of a word in the whole corpus\n",
    "        c=0\n",
    "    wordcount=dict(zip(uniq,lstc)) # dict of word and their count\n",
    "    final=[]\n",
    "    for i, j in wordcount.items():\n",
    "        idf= 1+ math.log((1+len(data))/(1+j)) #formula for IDF\n",
    "        final.append(idf)\n",
    "    idfdict= dict(zip(uniq,final)) #zipping word with its IDF value\n",
    "    return idfdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "final= compidf(uniq,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMPUTING A LIST OF DICTIONARIES WITH WORDS AS KEYS AND THEIR TF VALUES AS VALUES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'this': 0.2, 'is': 0.2, 'the': 0.2, 'first': 0.2, 'document': 0.2}, {'this': 0.16666666666666666, 'document': 0.3333333333333333, 'is': 0.16666666666666666, 'the': 0.16666666666666666, 'second': 0.16666666666666666}, {'and': 0.16666666666666666, 'this': 0.16666666666666666, 'is': 0.16666666666666666, 'the': 0.16666666666666666, 'third': 0.16666666666666666, 'one': 0.16666666666666666}, {'is': 0.2, 'this': 0.2, 'the': 0.2, 'first': 0.2, 'document': 0.2}]\n"
     ]
    }
   ],
   "source": [
    "tflist=d.copy()\n",
    "for idx, val in enumerate(b):\n",
    "    #print(idx, val)\n",
    "    zipper= list(zip(a[idx], val))\n",
    "    for i in zipper:\n",
    "        tflist[idx][i[0]]=i[1]\n",
    "print(tflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'this': 0.2, 'is': 0.2, 'the': 0.2, 'first': 0.2, 'document': 0.2},\n",
       " {'this': 0.16666666666666666,\n",
       "  'document': 0.3333333333333333,\n",
       "  'is': 0.16666666666666666,\n",
       "  'the': 0.16666666666666666,\n",
       "  'second': 0.16666666666666666},\n",
       " {'and': 0.16666666666666666,\n",
       "  'this': 0.16666666666666666,\n",
       "  'is': 0.16666666666666666,\n",
       "  'the': 0.16666666666666666,\n",
       "  'third': 0.16666666666666666,\n",
       "  'one': 0.16666666666666666},\n",
       " {'is': 0.2, 'this': 0.2, 'the': 0.2, 'first': 0.2, 'document': 0.2}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "\n",
      "0.2\n",
      "\n",
      "0.2\n",
      "\n",
      "0.2\n",
      "\n",
      "0.2\n",
      "\n",
      "0.2\n",
      "\n",
      "0.16666666666666669\n",
      "\n",
      "0.16666666666666669\n",
      "\n",
      "0.16666666666666669\n",
      "\n",
      "0.16666666666666669\n",
      "\n",
      "0.16666666666666669\n",
      "\n",
      "0.16666666666666669\n",
      "\n",
      "0.16666666666666669\n",
      "\n",
      "0.16666666666666669\n",
      "\n",
      "0.16666666666666669\n",
      "\n",
      "0.16666666666666669\n",
      "\n",
      "0.16666666666666669\n",
      "\n",
      "0.16666666666666669\n",
      "\n",
      "0.16666666666666669\n",
      "\n",
      "0.2\n",
      "\n",
      "0.2\n",
      "\n",
      "0.2\n",
      "\n",
      "0.2\n",
      "\n",
      "0.2\n",
      "\n",
      "0.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(tflist):\n",
    "    print(j[\"this\"])\n",
    "    print()\n",
    "    for word, tfval in j.items():\n",
    "        print(j[\"this\"])\n",
    "        print()\n",
    "        #print(word, tfval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MULTIPLICATION OF TF AND IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.2, 0.2, 0.3021651247531982, 0.24462871026284194, 0.16666666666666666, 0.40771451710473655, 0.16666666666666666, 0.16666666666666666, 0.3193817886456925, 0.3193817886456925, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.3193817886456925, 0.3193817886456925, 0.2, 0.2, 0.2, 0.3021651247531982, 0.24462871026284194]\n"
     ]
    }
   ],
   "source": [
    "tfidflist= tflist.copy()\n",
    "op=[]\n",
    "for idx, val in enumerate(tfidflist):\n",
    "    for key, kval in val.items():\n",
    "        nval= final[key]* kval\n",
    "        op.append(nval)\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(dataset,vocab,d):\n",
    "    rows = []\n",
    "    columns = []\n",
    "    values = []\n",
    "    if isinstance(dataset, (list,)):\n",
    "        a,b=comptf(d)\n",
    "        tflist=d.copy()\n",
    "        for idx, val in enumerate(b):\n",
    "            zipper= list(zip(a[idx], val))\n",
    "            for i in zipper:\n",
    "                tflist[idx][i[0]]=i[1]\n",
    "        for idx,row in enumerate(tflist):# for each dict in the tflist\n",
    "            for word, tfval in row.items():\n",
    "            # it will return a dict type object where key is the word and values is its TF Value, {word:TF Value}                \n",
    "                if len(word) < 2:\n",
    "                    continue\n",
    "                # we will check if its there in the vocabulary that we build in fit() function\n",
    "                # dict.get() function will return the values, if the key doesn't exits it will return -1\n",
    "                col_index = vocab.get(word, -1) # retreving the dimension number of a word\n",
    "                # if the word exists\n",
    "                if col_index !=-1:\n",
    "                    # we are storing the index of the document\n",
    "                    rows.append(idx)\n",
    "                    # we are storing the dimensions of the word\n",
    "                    columns.append(col_index)\n",
    "                    # we are storing the Mult of TF and IDF of the word\n",
    "                    tfidf= tfval*idfdict[word]\n",
    "                    values.append(tfidf)\n",
    "        return normalize(csr_matrix((values, (rows,columns)), shape=(len(dataset),len(vocab))))\n",
    "    else:\n",
    "        print(\"you need to pass list of strings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yup= transform(data,vocab,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]]\n"
     ]
    }
   ],
   "source": [
    "print(yup[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
